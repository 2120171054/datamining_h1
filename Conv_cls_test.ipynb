{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7eb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os,cv2\n",
    "import torch.nn as nn\n",
    "from cyvlfeat.kmeans import kmeans,kmeans_quantize\n",
    "from losses import relu_evidence\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "feats=np.load('record_feats_test.npy').astype(np.float32)\n",
    "data=np.reshape(feats,(feats.shape[0],-1))\n",
    "uncertianty=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0536efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=np.load('record_feats_train.npy').astype(np.float32)\n",
    "data=np.reshape(feats,(feats.shape[0],-1))\n",
    "\n",
    "if  not os.path.exists('sparse_labels.npy'):\n",
    "    print('clustering')\n",
    "    K=10\n",
    "    centers=kmeans(data,num_centers=K,initialization='PLUSPLUS',num_repetitions=10,\n",
    "                   max_num_comparisons=100,max_num_iterations=100,algorithm='LLOYD',num_trees=3)\n",
    "    labels=kmeans_quantize(data,centers)\n",
    "    # to get the sparse matrix of labels\n",
    "    sparse_labels=np.eye(K)[labels]\n",
    "    labels=labels.astype(np.float32)\n",
    "    sparse_labels=sparse_labels.astype(np.float32)\n",
    "\n",
    "    np.save('sparse_labels.npy',sparse_labels)\n",
    "    np.save('labels.npy',labels)\n",
    "else:\n",
    "    sparse_labels=np.load('sparse_labels.npy').astype(np.float32)\n",
    "    labels=np.load('labels.npy').astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1832981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "train_data_loadpath='/mnt/sda/sunche/datasets/Anomaly/Avenue/test/'\n",
    "train_label_loadpath='/mnt/sda/sunche/datasets/Anomaly/Avenue/avenue_gts.txt'\n",
    "def Gaussian(X,rate=0.05):\n",
    "    # Salt and pepper noise\n",
    "    drop = np.random.normal(0,rate, X.shape)\n",
    "    X=X+drop\n",
    "    return X\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_data_loadpath,labels,transform=None, target_transform=None,):\n",
    "        self.path=train_data_loadpath\n",
    "        self.files=os.listdir(train_data_loadpath)\n",
    "        self.inds=range(len(self.files))\n",
    "        self.gts=np.loadtxt(train_label_loadpath).astype(np.float32)\n",
    "        self.labels=labels\n",
    "    def __getitem__(self, index):\n",
    "        img_path=os.path.join(self.path,str(self.inds[index]+1)+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(img_path),(224,224))\n",
    "        img_npy=np.array(img).astype(np.float32)/255.0\n",
    "        \n",
    "#         img_npy = Gaussian(img_npy)\n",
    "        img_npy = np.reshape(img_npy,[224,224,3])\n",
    "        img_npy = np.transpose(img_npy,[2,0,1])\n",
    "        label=self.labels[index]\n",
    "\n",
    "        img_npy=torch.from_numpy(img_npy).float()\n",
    "#         label=torch.from_numpy(label).float()\n",
    "        return img_npy,label\n",
    "\n",
    "        return img_npy,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "# torch.set_num_threads(1)\n",
    "# train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE,num_workers=16, shuffle=True,pin_memory=False)  \n",
    "\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, feats, labels):\n",
    "#         self.feats=feats\n",
    "#         self.labels=labels\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.feats[index],self.labels[index]\n",
    "#     def __len__(self):\n",
    "#         return len(self.feats)\n",
    "BATCH_SIZE=32\n",
    "if uncertianty==False:\n",
    "    train_data=MyDataset(train_data_loadpath,labels)\n",
    "if uncertianty==True:\n",
    "    train_data=MyDataset(train_data_loadpath,labels)\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1,num_workers=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb67e5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG(\n",
       "    (conv3_64): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3_128): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3_256): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (conv3_512a): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (conv3_512b): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (bn1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (fc3): Linear(in_features=1024, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs, num_outputs, num_hiddens = data.shape[1], 10, 256\n",
    "import auto_encoders\n",
    "model = auto_encoders.VGG_11(20)\n",
    "\n",
    "epoch_=9\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()\n",
    "if uncertianty==False:\n",
    "    state = torch.load('./savepath_lstm_Net_6/cls_model'+str(epoch_+1)+'.pkl')['model_state']\n",
    "if uncertianty==True:\n",
    "    state = torch.load('./savepath_lstm_Net_6/cls_evi_model'+str(epoch_+1)+'.pkl')['model_state']\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f08f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "write_loss=np.zeros((0,1))\n",
    "for epoch in range(1):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    train_loss = 0.\n",
    "    for i,(batch_x, batch_y) in enumerate(train_loader):\n",
    "      batch_x = batch_x.cuda()\n",
    "      batch_y = batch_y.cuda()\n",
    "      out= model(batch_x)\n",
    "      _, preds = torch.max(out, 1)\n",
    "      if uncertianty==False:\n",
    "          scores=-np.max(out.data.cpu().numpy(),1)\n",
    "      if uncertianty==True:\n",
    "          evidence = relu_evidence(out)\n",
    "          alpha = evidence + 1\n",
    "          u = 20 / torch.sum(alpha, dim=1, keepdim=True)\n",
    "#           print(u.data.cpu().numpy().shape)\n",
    "          scores=np.max(u.data.cpu().numpy(),1)-np.mean(out.data.cpu().numpy(),1)\n",
    "      record_scores=scores\n",
    "#       for j in range(16):\n",
    "#           record_scores.append(scores)\n",
    "      write_loss=np.concatenate((write_loss,np.reshape(np.array(record_scores),(1,1))),0)\n",
    "if uncertianty==False:\n",
    "    np.save(\"total_loss_cls.npy\",np.array(write_loss))\n",
    "else:\n",
    "    np.save(\"total_loss_evi_t.npy\",np.array(write_loss))\n",
    "# exit()\n",
    "print('finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc_001",
   "language": "python",
   "name": "sc_001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
